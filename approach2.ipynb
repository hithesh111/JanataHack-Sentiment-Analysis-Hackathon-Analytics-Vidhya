{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>JanataHack Steam Reviews Sentiment Analysis Hackathon</h1>\n",
    "<h2>Approach 2 - Naive Bayes Classification</h2>\n",
    "Compared the probability of a review coming from either classes ('recommended' and 'not recommended') using Naive Bayes method and choosing the class with higher probability.\n",
    "Got 0.79 F1-score on the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing relevant libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load train and test datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>A littly iffy on the controls, but once you kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Great game, fun and colorful and all that.A si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spooky's Jump Scare Mansion</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Not many games have the cute tag right next to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                        title    year  \\\n",
       "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
       "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
       "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
       "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
       "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
       "\n",
       "                                         user_review  user_suggestion  \n",
       "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
       "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
       "2  A littly iffy on the controls, but once you kn...                1  \n",
       "3  Great game, fun and colorful and all that.A si...                1  \n",
       "4  Not many games have the cute tag right next to...                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/train.csv')\n",
    "df_test = pd.read_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combining reviews to make documents.</h3>\n",
    "Creating a document of all reviews in the training data, another document of all reviews in which the user recommends the game and another one which has all reviews in which user doesn't recommend the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ''\n",
    "doc1 = ''\n",
    "doc0 = ''\n",
    "for i in range(df.shape[0]):\n",
    "    doc = doc + df.loc[i,'user_review'] + str(' ')\n",
    "    if(df.loc[i,'user_suggestion']==0):\n",
    "        doc0 = doc0 + df.loc[i,'user_review'] + str(' ')\n",
    "    else:\n",
    "        doc1 = doc1 + df.loc[i,'user_review'] + str(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing the text in the three documents</h3>\n",
    "Removing stopwords (words which don't add relevant amount of meaning to sentences), keeping only alphabet characters and converting documents to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tokens = word_tokenize(doc)\n",
    "all_words = [token.lower() for token in tokens if token.isalpha()!=0]\n",
    "all_words = [word for word in all_words if word not in stop_words]\n",
    "\n",
    "tokens0 = word_tokenize(doc0)\n",
    "all_words0 = [token.lower() for token in tokens0 if token.isalpha()!=0]\n",
    "all_words0 = [word for word in all_words0 if word not in stop_words]\n",
    "\n",
    "tokens1 = word_tokenize(doc1)\n",
    "all_words1 = [token.lower() for token in tokens1 if token.isalpha()!=0]\n",
    "all_words1 = [word for word in all_words1 if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining and testing Conditional Probabilities</h3>\n",
    "Conditional probability of a word coming from negative review and from positive review, to be specific.<br>\n",
    "\n",
    "$P(word|class) = \\frac{n+\\alpha}{\\text{Total no of words in class } + \\alpha \\times \\text{vocabulary size}}$\n",
    "where $\\alpha$ is the smoothing parameter \n",
    "\n",
    "<h3>Add 1 smoothing ($\\alpha = 1$)</h3>\n",
    "We add 1 to the numerator and the total vocabulary size of the class document while computing probabilities to accomodate the words which never occured in the training text which will bring down the probability to zero in the probability computation of a class given a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good Good_review\n",
      "bad Bad_review\n",
      "cool Good_review\n",
      "gross Bad_review\n",
      "paid Bad_review\n",
      "sucks Bad_review\n",
      "worst Bad_review\n",
      "best Good_review\n",
      "yes Good_review\n",
      "amazing Good_review\n",
      "horrible Bad_review\n"
     ]
    }
   ],
   "source": [
    "def cond_prob(word,class_doc,main_doc_word_no,class_doc_word_no, alpha=1):\n",
    "    n = len(class_doc.lower().split(word)) - 1\n",
    "    prob = (n + alpha)/(class_doc_word_no + alpha*main_doc_word_no)\n",
    "    return prob    \n",
    "\n",
    "words = ['good', 'bad', 'cool', 'gross', 'paid', 'sucks','worst','best','yes','amazing','horrible']\n",
    "for word in words:\n",
    "    cond_p0 = cond_prob(word,doc0,len(all_words),len(all_words0))\n",
    "    cond_p1 = cond_prob(word,doc1,len(all_words),len(all_words1))\n",
    "    if(cond_p1 > cond_p0):\n",
    "        print(word,\"Good_review\")\n",
    "    else:\n",
    "        print(word,\"Bad_review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining conditional (log) probabilities for sentences</h3><br>\n",
    "By Bayes Theorem,\n",
    "$P(class|word) = \\frac{P(word|class)P(class)}{P(word)}$<br>\n",
    "Since we are considering the same word for both classes, we can ignore the denominator while comparing<br>\n",
    "$P(class|word) \\ \\propto \\ P(word|class)P(class)$\n",
    "\n",
    "One big assumption that the Naive Bayes Classifier makes is that each word in a document occur independently of eachother. <br><br>Then the conditional probability of a class given a sentence is the product (over all words) of conditional probabilities of the class given the word. (Log probabilities are used to avoid computational issues like probability vanishing to 0 which is quite probable when you mulitply a lot of probabilities) <br><br>\n",
    "$ P(class|sentence) = \\prod_{w \\ \\epsilon \\text{ sentence}} P(class|word) $<br>\n",
    "$ log(P(class|sentence)) = \\sum_{w \\ \\epsilon \\text{ sentence}} log(P(class|word)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_prob(paragraph,doc1,doc0,p0,p1,main_doc_word_no,class1_doc_word_no,class0_doc_word_no,alpha=1):\n",
    "    t0 = time()\n",
    "    log_cond_p1_para = log(p1)\n",
    "    log_cond_p0_para = log(p0)\n",
    "    words = set([word for word in word_tokenize(paragraph.lower())])\n",
    "    \n",
    "    for w in words:\n",
    "        log_cond_p1_para = log_cond_p1_para + log(cond_prob(w, doc1, main_doc_word_no, class1_doc_word_no,alpha))\n",
    "        log_cond_p0_para = log_cond_p0_para + log(cond_prob(w, doc0, main_doc_word_no, class0_doc_word_no,alpha))\n",
    "    \n",
    "    print(paragraph[:5])\n",
    "    if(log_cond_p1_para>=log_cond_p0_para):\n",
    "        print(\"Recommend\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Nope\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing the function</h3>\n",
    "p0 and p1 are class proportions (estimators of class probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad b\n",
      "Nope\n",
      "his i\n",
      "Recommend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = df['user_suggestion'].mean()\n",
    "p0 = 1 - p1\n",
    "\n",
    "NB_prob('Bad bad one, i don\\'t know what to say about this one. it is absolutely terrible',doc1,doc0,p0,p1,len(all_words),len(all_words1),len(all_words0))\n",
    "NB_prob('his is the best game I have ever played. I\\'m really excited for the next' ,doc1,doc0,p0,p1,len(all_words),len(all_words1),len(all_words0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment took very long to execute (around 22 hours). Therefore I had to break it down and predict for one group of test examples at a time. Hence the 'read_csv' and 'commented zero series' code segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Inter\n",
      "Recommend\n",
      "Thank\n",
      "Recommend\n",
      "For a\n",
      "Recommend\n",
      "A rat\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "This \n",
      "Recommend\n",
      "Playe\n",
      "Nope\n",
      "This \n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Guns \n",
      "Recommend\n",
      "Early\n",
      "Nope\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "This \n",
      "Recommend\n",
      "(said\n",
      "Recommend\n",
      "im go\n",
      "Recommend\n",
      "This \n",
      "Recommend\n",
      "For f\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "TL;DR\n",
      "Recommend\n",
      "I lov\n",
      "Recommend\n",
      "pile \n",
      "Nope\n",
      "New u\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "This \n",
      "Recommend\n",
      "This \n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "It is\n",
      "Recommend\n",
      "Early\n",
      "Recommend\n",
      "After\n",
      "Recommend\n",
      "Pros:\n",
      "Recommend\n",
      "Actua\n",
      "Recommend\n",
      "see p\n",
      "Recommend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hithesh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/nlp_sub2.csv')\n",
    "df_test['user_suggestion'] = data['user_suggestion']\n",
    "# df_test['user_suggestion'] = pd.Series(np.zeros(df_test.shape[0]))\n",
    "df_test['user_suggestion'][8000:] = df_test['user_review'][8000:].apply(lambda x: int(NB_prob(x,doc1,doc0,p0,p1,len(all_words),len(all_words1),len(all_words0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([df_test['review_id'],df_test['user_suggestion']],axis=1)\n",
    "final.to_csv('/home/hithesh/Desktop/ML Competitions/Sentiment_Analysis_Analytics_vidhya/nlp_sub2.csv',header=True , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
